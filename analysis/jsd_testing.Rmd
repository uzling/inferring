---
title: "JSD_testing"
author: "Nicholas Lester"
date: "9/24/2020"
output:
  github_document:
  pandoc_args: --webtex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE, warning=F, message=F)
```

### Summary
This file analyzes and compares the distributions of phonemes in three databases: BDPROTO (ancient attested/reconstructed languages), PHOIBLE (modern languages), and SegBo (segments known to be borrowed into inventories).

In **Section 1**, we test the overall similarity of each of the databases to each other. Similarity is operationalized as the Kullback-Leibler divergence between the frequency distributions of segments in the databases. We also explore in what ways these similarity estimates might be affected by individual segments, macroareas, or segment class.

In **Section 2**, we attempt to correct against sampling biases in the databases by resampling segments in two ways: one sound per language and one language per family). The resulting frequency distributions are then compared as in Section 1. A random baseline is established for each comparison by scrambling the mapping of segment to frequency in each randomly sampled distribution.

First, clear memory (optional)
```{r clear_mem}
rm(list=ls(all=T))
```

Load libraries
```{r libraries}
library(philentropy)
library(tidyverse)
library(dplyr)
library(mgcv)
library(MASS)
library(ggplot2)
library(effects)
library(extrafont)
library(ggpubr)
```

Load the data
- **all_dbs_all_segments**: full inventories for all three databases
- **all_segments_long**: frequency counts for segments in the three databases
- **families_segments_long**: frequencies for BDPROTO and PHOIBLE controlled for families
- **intersect_families_segments_long**: frequencies for BDPROTO, PHOIBLE, and SegBo controlled for overlapping families
- **isolates**: languages labeled isolates within Glottolog
```{r load_data}
load("./data.RData") 

# Some cleanup
all_dbs_all_segments = all_dbs_all_segments %>% mutate(Database = recode(Database, 
                                                       bdproto = "BDPROTO", 
                                                       phoible = "PHOIBLE", 
                                                       segbo = "SegBo"))

all_dbs_all_segments$Database = factor(all_dbs_all_segments$Database, 
                                       levels = c("PHOIBLE", "BDPROTO", "SegBo"))

all_segments_long = as.data.frame(all_segments_long)

families_segments_long = as.data.frame(families_segments_long)

intersect_families_segments_long = as.data.frame(intersect_families_segments_long)

isolates = read.table("./isolates.txt", header=T, sep="\t", comment.char="", quote="")$id
```

Let's compare the segment counts of the different databases
```{r basic_count_data}
# Overall segment counts
counts = all_dbs_all_segments %>% group_by(Database) %>%
                                  summarize(NumberOfSegments = n(), 
                                            NumberOfSegmentTypes = length(unique(Phoneme)))

counts.consonants = all_dbs_all_segments %>% 
                    filter(SegmentClass == "consonant") %>%
                    group_by(Database) %>%
                    summarize(NumberOfSegments = n(), 
                              NumberOfSegmentTypes = length(unique(Phoneme)))

counts.vowels = all_dbs_all_segments %>% 
                filter(SegmentClass == "vowel") %>%
                group_by(Database) %>%
                summarize(NumberOfSegments = n(), 
                         NumberOfSegmentTypes = length(unique(Phoneme)))

# Plot the frequencies
## All segments
### Token counts
all.token.counts = ggplot(counts, aes(x=Database, y=NumberOfSegments)) +
      geom_bar(stat="identity") +
      ylab("Number of segments") +
      ggtitle("Segment token counts") +
      theme_bw() + 
      theme(plot.title = element_text(hjust = 0.5)) 

all.token.counts

### Type counts
all.type.counts = ggplot(counts, aes(x=Database, y=NumberOfSegmentTypes)) +
      geom_bar(stat="identity") +
      ylab("Number of segment types") +
      ggtitle("Segment type counts") +
      theme_bw() + 
      theme(plot.title = element_text(hjust = 0.5)) 

all.type.counts

## Consonants only
### Token counts
con.token.counts = ggplot(counts.consonants, aes(x=Database, y=NumberOfSegments)) +
      geom_bar(stat="identity") +
      ylab("Number of segments") +
      ggtitle("Segment token counts (consonants)") +
      theme_bw() + 
      theme(plot.title = element_text(hjust = 0.5)) 

con.token.counts

### Type counts
con.type.counts = ggplot(counts.consonants, aes(x=Database, y=NumberOfSegmentTypes)) +
      geom_bar(stat="identity") +
      ylab("Number of segment types") +
      ggtitle("Segment type counts (consonants)") +
      theme_bw() + 
      theme(plot.title = element_text(hjust = 0.5)) 

con.type.counts

## Vowels only
### Token counts
vow.token.counts = ggplot(counts.vowels, aes(x=Database, y=NumberOfSegments)) +
      geom_bar(stat="identity") +
      ylab("Number of segments") +
      ggtitle("Segment token counts (vowels)") +
      theme_bw() + 
      theme(plot.title = element_text(hjust = 0.5)) 

vow.token.counts

### Type counts
vow.type.counts = ggplot(counts.vowels, aes(x=Database, y=NumberOfSegmentTypes)) +
      geom_bar(stat="identity") +
      ylab("Number of segment types") +
      ggtitle("Segment type counts (vowels)") +
      theme_bw() + 
      theme(plot.title = element_text(hjust = 0.5)) 

vow.type.counts


# ...and broken down by macroarea
counts.macro = all_dbs_all_segments %>% 
               group_by(Database, macroarea) %>%
               summarize(NumberOfSegments = n(), 
                         NumberOfSegmentTypes = length(unique(Phoneme)))

counts.macro.consonants = all_dbs_all_segments %>% 
                          filter(SegmentClass == "consonant") %>%
                          group_by(Database, macroarea) %>%
                          summarize(NumberOfSegments = n(), 
                                    NumberOfSegmentTypes = length(unique(Phoneme)))

counts.macro.vowels = all_dbs_all_segments %>% 
                      filter(SegmentClass == "vowel") %>%
                      group_by(Database, macroarea) %>%
                      summarize(NumberOfSegments = n(), 
                                NumberOfSegmentTypes = length(unique(Phoneme)))

# Proportion of each macroarea per corpus
propMacro = function(countsTotal, countsMacro){
    props = vector()
    database.counts = vector()
    for(db in countsTotal$Database){
        n = countsTotal$NumberOfSegments[countsTotal$Database==db]
        for(count in countsMacro$NumberOfSegments[countsMacro$Database==db]){
            prop = count/n
            props = c(props, prop)
            database.counts = c(database.counts, n)
        }
    }
    countsMacro$ProportionOfDatabase = props
    countsMacro$DatabaseSize = database.counts
    return(countsMacro)
}

# Total counts
counts.macro = propMacro(counts, counts.macro); 
as.data.frame(counts.macro)

# Consonants only
counts.macro.consonants = propMacro(counts.consonants, counts.macro.consonants); as.data.frame(counts.macro.consonants)

# Vowels only
counts.macro.vowels = propMacro(counts.vowels, counts.macro.vowels); 
as.data.frame(counts.macro.vowels)

# Plot the proportions of sample size per macroarea
## Total counts
p.total.cts = ggplot(counts.macro, aes(x = macroarea, y=ProportionOfDatabase, group=Database, fill=Database)) +
      geom_bar(stat="identity", position="dodge", color="black") +
      ylab("Proportion of database (%)") +
      xlab("Macroarea") +
      ggtitle("Sample size by macroarea") +
      theme_bw() + 
      theme(plot.title = element_text(hjust = 0.5)) 

p.total.cts

## Consonants only
p.consonant.cts = ggplot(counts.macro.consonants, aes(x = macroarea, y=ProportionOfDatabase, group=Database, fill=Database)) +
      geom_bar(stat="identity", position="dodge", color="black") +
      ylab("Proportion of database (%)") +
      xlab("Macroarea") +
      ggtitle("Sample size by macroarea (consonants)") +
      theme_bw() + 
      theme(plot.title = element_text(hjust = 0.5)) 

p.consonant.cts

## Vowels only
p.vowel.cts = ggplot(counts.macro.vowels, aes(x = macroarea, y=ProportionOfDatabase, group=Database, fill=Database)) +
      geom_bar(stat="identity", position="dodge", color="black") +
      ylab("Proportion of database (%)") +
      xlab("Macroarea") +
      ggtitle("Sample size by macroarea (vowels)") +
      theme_bw() + 
      theme(plot.title = element_text(hjust = 0.5)) 

p.vowel.cts

```

Clearly, PHOIBLE is much larger than the other two databases. BDPROTO is second largest (though much smaller than PHOIBLE), and is roughly four times as large as SegBo.

The plot of sample size by macroarea shows that each database favors one or more macroareas more than the other two: for PHOIBLE, African and Australian languages; for BDPROTO, North American languages (and to a lesser extent, Eurasian languages); and for SegBo, Papunesian languages. Furthermore, SegBo contains much richer coverage of vowels than consonants in Australia. Finally, the overall proportions (i.e., all segment types considered) more closely resemble the distributional biases we see for consonants across macroareas than for vowels. 

**Section 1**: Global comparisons of the databases

Create sets of two vectors based on the contrasts of interest
```{r contrasts}
# Extract the vectors the we will compare

## Family-controlled frequencies
bd.pho.fam = rbind(families_segments_long[,2], families_segments_long[,3])

bd.seg.fam = rbind(intersect_families_segments_long[,3], intersect_families_segments_long[,4])

pho.seg.fam = rbind(intersect_families_segments_long[,2], intersect_families_segments_long[,4])

## Total frequencies
bd.pho.all = rbind(all_segments_long[,3], all_segments_long[,2])

pho.seg.all = rbind(all_segments_long[,2], all_segments_long[,4])

bd.seg.all = rbind(all_segments_long[,3], all_segments_long[,4])
```

Compute JSDs
```{r jsd}
## Family-controlled frequencies
jsd.bd.pho.fam = suppressMessages(JSD(bd.pho.fam, unit = "log2", est.prob="empirical"))
jsd.bd.seg.fam = suppressMessages(JSD(bd.seg.fam, unit = "log2", est.prob="empirical"))
jsd.pho.seg.fam = suppressMessages(JSD(pho.seg.fam, unit = "log2", est.prob="empirical"))
jsd.fam = c(jsd.bd.pho.fam, jsd.bd.seg.fam, jsd.pho.seg.fam)

## Total frequencies
jsd.bd.pho.all = suppressMessages(JSD(bd.pho.all, unit = "log2", est.prob="empirical"))
jsd.pho.seg.all = suppressMessages(JSD(pho.seg.all, unit = "log2", est.prob="empirical"))
jsd.bd.seg.all = suppressMessages(JSD(bd.seg.all, unit = "log2", est.prob="empirical"))
jsd.all = c(jsd.bd.pho.all, jsd.bd.seg.all, jsd.pho.seg.all)

# Plot the results
## Create a dataframe
jsd.table = data.frame(JSD = c(jsd.fam,
                               jsd.all),
                       FreqType = c(rep("Family-controlled", 3),
                                    rep("Total", 3)),
                       CompType = c(rep(c("BDPROTO-PHOIBLE",
                                          "BDPROTO-SegBo",
                                          "PHOIBLE-SegBo"), 2)))
## Cleveland's dotplot
dotchart(jsd.table$JSD,
         labels=jsd.table$CompType,
         groups=jsd.table$FreqType, 
         color=rep(c("red", "blue", "black"), 2),
         xlab="JSD",
         main="more similar ↔ less similar")
```

Recompute JSD based on a leave-one-out (LOO) sampling method.
```{r loo}
# Regarding the plots: sounds on the left edge are responsible for distinguishing the two databases; sounds on the right edge are responsible for binding them (the sounds that make them the most similar). These can also be seen by examining the ordered dataframes.

# Function to leave out a segments, compute JSD, and record both the left-out segment and the resulting JSD
loo_jsd = function(long.df, p, q, jsd.input.type="counts"){
    jsd.list = list()
    for(i in 1:nrow(long.df)){
        current.phoneme = long.df$Phoneme[i]
        loo.df = as.data.frame(long.df %>% filter(Phoneme != current.phoneme))
        p.dist = as.vector(loo.df[,p])
        q.dist = as.vector(loo.df[,q])
        jsd.df = rbind(p.dist, q.dist)
        if(jsd.input.type == "counts"){
            current.jsd = suppressMessages(JSD(jsd.df, est.prob="empirical"))
        }
        else{
            current.jsd = suppressMessages(JSD(jsd.df))
        }
        current.row = data.frame(Dropped_Phoneme = current.phoneme, JSD = current.jsd, SourceDB = p, TargetDB = q)
        jsd.list[[i]] = current.row
    }
    jsd.tab = do.call(rbind, jsd.list)
    jsd.tab = jsd.tab[with(jsd.tab, order(JSD)),]

    # Produce a plot of the segments by how much their absence
    # contributes to the change in JSD
    segPlot = ggplot(jsd.tab, aes(x = seq(1:nrow(jsd.tab)), y = JSD, label = Dropped_Phoneme)) +
    geom_text() +
    ggtitle(paste0("Leave-one-out JSDs: ", p, " → ", q)) +
    xlab("Rank") +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5))

    return(list(jsd.tab, segPlot))
}

# Family-controlled frequencies
## BDPROTO vs. PHOIBLE
loo.bd.pho.fam = loo_jsd(families_segments_long, "bdproto", "phoible")

head(loo.bd.pho.fam[[1]], 20)
tail(loo.bd.pho.fam[[1]], 20)

p.loo.bd.pho.fam = loo.bd.pho.fam[[2]]; p.loo.bd.pho.fam

## BDPROTO vs. SegBo
loo.bd.seg.fam = loo_jsd(intersect_families_segments_long, "bdproto", "segbo")

head(loo.bd.seg.fam[[1]], 20)
tail(loo.bd.seg.fam[[1]], 20)

p.loo.bd.seg.fam = loo.bd.seg.fam[[2]]; p.loo.bd.seg.fam

## PHOIBLE vs. SegBo
loo.pho.seg.fam = loo_jsd(intersect_families_segments_long, "phoible", "segbo")

head(loo.pho.seg.fam[[1]], 20)
tail(loo.pho.seg.fam[[1]], 20)

p.loo.pho.seg.fam = loo.pho.seg.fam[[2]]; p.loo.pho.seg.fam

# Total frequencies
## BDPROTO vs. PHOIBLE
loo.bd.pho.all = loo_jsd(all_segments_long, "bdproto", "phoible")

head(loo.bd.pho.all[[1]], 20)
tail(loo.bd.pho.all[[1]], 20)

p.loo.bd.pho.all = loo.bd.pho.all[[2]]; p.loo.bd.pho.all

## BDPROTO vs. SegBo
loo.bd.seg.all = loo_jsd(all_segments_long, "bdproto", "segbo")

head(loo.bd.seg.all[[1]], 20)
tail(loo.bd.seg.all[[1]], 20)

p.loo.bd.seg.all = loo.bd.seg.all[[2]]; p.loo.bd.seg.all


## PHOIBLE vs. SegBo
loo.pho.seg.all = loo_jsd(all_segments_long, "phoible", "segbo")

head(loo.pho.seg.all[[1]], 20)
tail(loo.pho.seg.all[[1]], 20)

p.loo.pho.seg.all = loo.pho.seg.all[[2]]; p.loo.pho.seg.all
```

Note that the variability falls in a very narrow range, indicating that (a) there is a high degree of similarity between the frequency distributions in the PHOIBLE and BDPROTO databases, and (b) only a relatively small number of segments play any role in distinguishing the databases.

Now let's model differences between PHOIBLE and BDPROTO as they relate to SegBo frequencies.

```{r modeling_diffs_pho_bdproto}
scaling.func = function(variable, n=10){
    min.var = min(variable)
    range.var = max(variable)-min.var
    scaled.var = ((variable - min.var)/range.var)*n
    return(scaled.var)
}

freq.mod = function(df, plot.title){
    mod.dat = df
      
    # Scale the variables (sample sizes and scales are different; 
    # this makes the numbers comparable)
    mod.dat$phoible.scaled = scaling.func(mod.dat$phoible)
    mod.dat$bdproto.scaled = scaling.func(mod.dat$bdproto)

    # Turn into long format
    mod.dat.long = data.frame(Phoneme = rep(mod.dat$Phoneme, 2),
                              Frequency.scaled = c(mod.dat$phoible.scale,
                                                   mod.dat$bdproto.scaled),
                              Frequency.source = c(rep("phoible", 
                                                       length(mod.dat$phoible.scaled)), 
                                                   rep("bdproto",
                                                       length(mod.dat$bdproto.scaled))))
    # Add the SegBo frequencies
    mod.dat.long = left_join(mod.dat.long, 
                             df[, c("Phoneme", "segbo")],
                             by="Phoneme")
    
    # Modeling (7th order polynomial decided on basis of initial exploratory GAM)
    mod = glm(segbo ~ poly(Frequency.scaled,7)*Frequency.source, data = mod.dat.long, family="quasipoisson" )

    # Plotting results
    hyp.data = expand.grid(Frequency.scaled = seq(0, 10), 
                           Frequency.source = c("phoible", "bdproto"))

    # Get predicted values
    preds.hyp = predict(mod, newdata=hyp.data, type="response", se.fit=T)

    # Compute upper and lower standard errors
    hyp.data = cbind(hyp.data,
                     SegBo = preds.hyp$fit, 
                     upper = preds.hyp$fit + preds.hyp$se.fit, 
                     lower = preds.hyp$fit - preds.hyp$se.fit)

    # Fix factor levels
    hyp.data$Frequency.source = toupper(hyp.data$Frequency.source)

    # Plotting
    p = ggplot(hyp.data, aes(y=SegBo, x=Frequency.scaled, group=Frequency.source,  fill=Frequency.source)) + 
          geom_line() + 
          geom_ribbon(aes(ymin=lower,ymax=upper), alpha=0.7) +
          xlab("Inventory frequency (scaled)") +
          ylab("Predicted SegBo frequency") +
          ggtitle(plot.title) +
          scale_fill_manual(values=c("lightblue", "darkred"),
                            name="Database") +
          theme_bw() +
          theme(plot.title = element_text(hjust=0.5))

    return(list(mod, p, mod.dat.long))
}

# Comparing BDPROTO to PHOIBLE, all segments
bd.pho.contrast.allsegs = freq.mod(intersect_families_segments_long, "BDPROTO vs. PHOIBLE")
anova(bd.pho.contrast.allsegs[[1]], test="Chisq")

poisson.all = bd.pho.contrast.allsegs[[2]]; poisson.all

```

We next examine the segments that fall in the frequency bands which best distinguish PHOIBLE and BDPROTO regarding their respective similarities to SegBo. This is similar to what we do with the LOO sampling above; however, in this case, we are interested in which segments contribute to the difference in similarity between PHOIBLE and BDPROTO to SegBo, as opposed to looking at which segments distinguish any single pair of databases from each other.

```{r segments_that_distinguish_phoible_and_segbo}
find.segs = function(df, min, max, sourceDB){
                     out.df = df %>%
                              filter(Frequency.source == sourceDB & 
                                     Frequency.scaled >= min &
                                     Frequency.scaled <= max) %>%
                              arrange(-segbo)
                     return(out.df)
}

# Scale segbo frequencies
segbo.scaled = data.frame(Phoneme = intersect_families_segments_long$Phoneme, segbo.scaled = scaling.func(intersect_families_segments_long$segbo))

# Middle values of x-axis
## BDPROTO
diff.bdproto.mid = find.segs(bd.pho.contrast.allsegs[[3]], 3, 6, "bdproto")
diff.bdproto.mid = left_join(diff.bdproto.mid, segbo.scaled, by="Phoneme")
diff.bdproto.mid$Phoneme

## PHOIBLE
diff.phoible.mid = find.segs(bd.pho.contrast.allsegs[[3]], 3, 6, "phoible")
diff.phoible.mid = left_join(diff.phoible.mid, segbo.scaled, by="Phoneme")
diff.phoible.mid$Phoneme

# Low values of x-axis
## BDPROTO
diff.bdproto.low = find.segs(bd.pho.contrast.allsegs[[3]], 0, 2.5, "bdproto")
diff.bdproto.low = left_join(diff.bdproto.low, segbo.scaled, by="Phoneme")
head(diff.bdproto.low$Phoneme, 20)

## PHOIBLE
diff.phoible.low = find.segs(bd.pho.contrast.allsegs[[3]], 0, 2.5, "phoible")
diff.phoible.low = left_join(diff.phoible.low, segbo.scaled, by="Phoneme")
head(diff.phoible.low$Phoneme, 20)

```

Because vowels are in general less likely to be borrowed than consonants, and certain sounds are more difficult/less likely to reconstruct (e.g., labiodentals), we restrict our dataset in two additional ways. First, we rerun the above analysis only on consonants. Then, we do the same, but removing labiodentals /f,v/ from the databases.

```{r remove_labiodentals}
fam.seg = left_join(intersect_families_segments_long, 
                    unique(all_dbs_all_segments[,c("Phoneme", "SegmentClass")]),
                    by = "Phoneme")

###########################################
# Keep consonants, but not vowels and tones
###########################################
fam.con = fam.seg %>% filter(SegmentClass == "consonant")
fam.con.contrast = freq.mod(fam.con, "BDPROTO vs. PHOIBLE (consonants)")
anova(fam.con.contrast[[1]], test="Chisq")
poisson.consonants.all = fam.con.contrast[[2]]; poisson.consonants.all

# Middle values of x-axis
## BDPROTO
diff.bdproto.mid.con = find.segs(fam.con.contrast[[3]], 3, 6, "bdproto")
diff.bdproto.mid.con$Phoneme

## PHOIBLE
diff.phoible.mid.con = find.segs(fam.con.contrast[[3]], 3, 6, "phoible")
diff.phoible.mid.con$Phoneme

# Low values of x-axis
## BDPROTO
diff.bdproto.low.con = find.segs(fam.con.contrast[[3]], 0, 2.5, "bdproto")
head(diff.bdproto.low.con$Phoneme, 20)

## PHOIBLE
diff.phoible.low.con = find.segs(fam.con.contrast[[3]], 0, 2.5, "phoible")
head(diff.phoible.low.con$Phoneme, 20)

################################################################
# Knock out labiodentals, but keep consonants, vowels, and tones
#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
fam.sans.ld = fam.seg %>% filter(!fam.seg$Phoneme %in% c("f", "v"))
fam.sans.ld.contrast = freq.mod(fam.sans.ld, "BDPROTO vs. PHOIBLE (no labiodentals)")
anova(fam.sans.ld.contrast[[1]], test="Chisq")
poisson.nold.all = fam.sans.ld.contrast[[2]]; poisson.nold.all

# Middle values of x-axis
## BDPROTO
diff.bdproto.mid.ld = find.segs(fam.sans.ld.contrast[[3]], 3, 6, "bdproto")
diff.bdproto.mid.ld$Phoneme

## PHOIBLE
diff.phoible.mid.ld = find.segs(fam.sans.ld.contrast[[3]], 3, 6, "phoible")
diff.phoible.mid.ld$Phoneme

# Low values of x-axis
## BDPROTO
diff.bdproto.low.ld = find.segs(fam.sans.ld.contrast[[3]], 0, 2.5, "bdproto")
head(diff.bdproto.low.ld$Phoneme, 20)

## PHOIBLE
diff.phoible.low.ld = find.segs(fam.sans.ld.contrast[[3]], 0, 2.5, "phoible")
head(diff.phoible.low.ld$Phoneme, 20)

######################################################
# Knock out labiodentals, but only consider consonants
######################################################
fam.con.sans.ld = fam.sans.ld %>% filter(SegmentClass == "consonant")
fam.con.sans.ld.contrast = freq.mod(fam.con.sans.ld, "BDPROTO vs. PHOIBLE (consonants, no labiodentals)")
anova(fam.con.sans.ld.contrast[[1]], test="Chisq")
poisson.consonants.nold.all = fam.con.sans.ld.contrast[[2]]; poisson.consonants.nold.all

# Middle values of x-axis
## BDPROTO
diff.bdproto.mid.ld = find.segs(fam.con.sans.ld.contrast[[3]], 3, 6, "bdproto")
diff.bdproto.mid.ld$Phoneme

## PHOIBLE
diff.phoible.mid.ld = find.segs(fam.con.sans.ld.contrast[[3]], 3, 6, "phoible")
diff.phoible.mid.ld$Phoneme

# Low values of x-axis
## BDPROTO
diff.bdproto.low.ld = find.segs(fam.con.sans.ld.contrast[[3]], 0, 2.5, "bdproto")
head(diff.bdproto.low.ld$Phoneme, 20)

## PHOIBLE
diff.phoible.low.ld = find.segs(fam.con.sans.ld.contrast[[3]], 0, 2.5, "phoible")
head(diff.phoible.low.ld$Phoneme, 20)

```
By considering only consonants, we do not observe a significant change in the behavior of the two databases. However, removing labiodentals (everything else held constant), draws BDPROTO and PHOIBLE into much closer alignment. Nevertheless, we still observe the crossing at roughly 2.5 on the x-axis, with too few mid-borrowability forms in BDPROTO and a stronger peak in PHOIBLE for mid-level frequencies. The image is a bit more difficult when we consider only consonants without the labiodentals. In this case, we see a stronger peak for BDPROTO in the higher frequncy ranges (i.e., BDPROTO contains more instances of sounds that are also highly borrowable). But the general picture is similar, and we still observe the cross-over in the lower frequency ranges. In other words, BDPROTO has too few mid-level borrowable segments and too many low- and high-borrowability segments relative to PHOIBLE.   

*Interpretation*: Over time, the most borrowable sounds are drawn towards the median frequency band across languages. Conversely, the least borrowable sounds are drawn to the extremes of the frequency range. This fits with the idea that both typologically dispreferred sounds (e.g., sounds that are rare because they are difficult to articulate/perceive) and sounds that are typologically heavily preferred (i.e., the sounds that languages tend to already have) are the least likely to be borrowed in contact scenarios.

Also, as Eitan points out, the largest discrepancy between BDPROTO and PHOIBLE arises for those sounds that are the most frequent in SegBo.

**Section 2**: Random resampling to guard against biases in the databases

First, we define some functions to perform the resampling.
```{r random_resampling}
# Relabel isolate families as "isolate" for the OIPF sampling (i.e., group them together to avoid an assured selection of all isolate selections on each iteration).
all_dbs_all_segments$family_id_simplified = as.factor(ifelse(all_dbs_all_segments$Glottocode %in% isolates, "isolate", as.vector(all_dbs_all_segments$family_id)))

# Function to generate frequency distributions by one of two methods:
# one sound per language ("ospl") or one inventory per family ("oipf")
sampling.fnc = function(df, method){
    # OSPL
    if(method=="ospl"){
        seg.df = df %>% group_by(InventoryID) %>%
                            summarize(Phoneme = sample(Phoneme,1))
        seg.cts = seg.df %>% group_by(Phoneme) %>%
                          summarize(Frequency = n())
    }
    # OIPF    
    else if(method=="oipf"){
        seg.list = list()
        fams = unique(df$family_id_simplified)
        i=1
        for(fam in fams){
            langs = unique(df$InventoryID[df$family_id_simplified==fam])
            lang = sample(langs,1)
            curr.segs = df[df$InventoryID==lang, c("Phoneme", "InventoryID")]
            seg.list[[i]] = curr.segs
            i = i+1
        }
        seg.df = do.call(rbind, seg.list)
        seg.cts = seg.df %>% group_by(Phoneme) %>%
                             summarize(Frequency = n())
    }
    output.df = as.data.frame(seg.cts)
    return(output.df)
}

# Function to combine and compare randomly generated distributions
iter.jsd = function(df, k, segment.class, geo, db.p, db.q, method, distinctiveSegbo=F){
      if(distinctiveSegbo==T){
          seg = as.vector(df$Glottocode[df$Database=="segbo"])
          oth = as.vector(df$Glottocode[df$Database==db.p])
          shared.langs = intersect(seg, oth)
          new.df.p = df[!df$Glottocode %in% shared.langs,]
      }
      new.df.p = df %>% filter(SegmentClass %in% c(segment.class) &
                           macroarea %in% c(geo) &
                           Database %in% c(db.p))
      new.df.q = df %>% filter(SegmentClass %in% c(segment.class) &
                           macroarea %in% c(geo) &
                           Database %in% c(db.q))
      pTqT.vec = vector()
      pTqF.vec = vector()
      pFqT.vec = vector()
      pFqF.vec = vector()
      for(i in 1:k){
          p.sample.true = sampling.fnc(new.df.p, method)
          p.sample.random = data.frame(Phoneme = p.sample.true$Phoneme,
                                       Frequency = sample(p.sample.true$Frequency))
          q.sample.true = sampling.fnc(new.df.q, method)
          q.sample.random = data.frame(Phoneme = q.sample.true$Phoneme,
                                       Frequency = sample(q.sample.true$Frequency))
          pTqT = merge(p.sample.true, q.sample.true, all = T, by="Phoneme")
          pTqT = as.data.frame(apply(pTqT[,2:3], 2, function(x){ifelse(is.na(x), 0, x)}))
          pTqF = merge(p.sample.true, q.sample.random, all = T, by="Phoneme")
          pTqF = as.data.frame(apply(pTqF[,2:3], 2, function(x){ifelse(is.na(x), 0, x)}))          
          pFqT = merge(p.sample.random, q.sample.true, all = T, by="Phoneme")
          pFqT = as.data.frame(apply(pFqT[,2:3], 2, function(x){ifelse(is.na(x), 0, x)}))    
          pFqF = merge(p.sample.random, q.sample.random, all = T, by="Phoneme")
          pFqF = as.data.frame(apply(pFqF[,2:3], 2, function(x){ifelse(is.na(x), 0, x)}))   
          # Estimate JSDs for each comparison
          pTqT.jsd = JSD(t(pTqT), est.prob="empirical")
          pTqF.jsd = JSD(t(pTqF), est.prob="empirical")
          pFqT.jsd = JSD(t(pFqT), est.prob="empirical")
          pFqF.jsd = JSD(t(pFqF), est.prob="empirical")
          pTqT.vec = c(pTqT.vec, pTqT.jsd)
          pTqF.vec = c(pTqF.vec, pTqF.jsd)
          pFqT.vec = c(pFqT.vec, pFqT.jsd)
          pFqF.vec = c(pFqF.vec, pFqF.jsd)
      }
      total.length = sum(length(pTqT.vec),
                         length(pTqF.vec),
                         length(pFqT.vec),
                         length(pFqF.vec))
      output.df = data.frame(JSD = c(pTqT.vec, 
                                     pTqF.vec, 
                                     pFqT.vec, 
                                     pFqF.vec), 
                             CompType = c(rep("True-True", 
                                              length(pTqT.vec)),
                                          rep("True-False",
                                              length(pTqF.vec)),
                                          rep("False-True",
                                              length(pFqT.vec)),
                                          rep("False-False",
                                              length(pFqF.vec))),
                              SegmentClass = rep(paste(segment.class, collapse="+"), 
                                               total.length),
                              macroarea = gsub(" ", "_", rep(paste(geo, collapse="+"),
                                              total.length), perl=T),
                              db.p = rep(db.p,
                                         total.length),
                              db.q = rep(db.q,
                                         total.length),
                              method = rep(method,
                                           total.length))
      return(output.df)
}

# Function to perform the whole analysis over each of the various variable combinations
iter.param = function(df, k, distinctiveSegbo=F){
    db.ps = unique(df$Database)
    db.qs = unique(df$Database)
    segment.classes = c("consonant", "vowel", "cv")
    macroareas = c(unique(df$macroarea), "all")
    methods = c("ospl", "oipf")
    p.space = expand.grid(db.p = db.ps,
                          db.q = db.qs,
                          SegmentClass = segment.classes, 
                          macroarea = macroareas, 
                          method = methods)
    p.space = droplevels(p.space[p.space$db.p != p.space$db.q,])
    p.space = droplevels(p.space[(p.space$db.q != "bdproto") &
                       (p.space$db.p != "segbo"),])
    p.space = na.omit(p.space)
    jsd.list = list()
    for(i in 1:nrow(p.space)){
        if(p.space$SegmentClass[[i]] == "cv"){
            seg.arg = c("consonant", "vowel")
        }
        else{
            seg.arg = as.vector(p.space$SegmentClass[i])
        }
        if(p.space$macroarea[[i]] == "all"){
            area.arg = as.vector(unique(df$macroarea))
        }
        else{
            area.arg = as.vector(p.space$macroarea[[i]])
        }
        if(distinctiveSegbo == T){
            current.iter = iter.jsd(df, 
                                    k,
                                    seg.arg, 
                                    area.arg,
                                    as.vector(p.space$db.p[i]),
                                    as.vector(p.space$db.q[i]),
                                    as.vector(p.space$method[i]),
                                    T)
        }
        else{
            current.iter = iter.jsd(df, 
                                    k,
                                    seg.arg, 
                                    area.arg,
                                    as.vector(p.space$db.p[i]),
                                    as.vector(p.space$db.q[i]),
                                    as.vector(p.space$method[i]))
        }
        jsd.list[[i]] = current.iter
    }
    output.df = do.call(rbind, jsd.list)
    return(output.df)
}

# Function to plot the distributions of the JSD values
distPlotter = function(df, title, seg.class, geo, source.db, target.db, sampleType, contrastType, comp.type=NULL){
      if(contrastType=="within"){
          plot.df = df %>% filter(SegmentClass == seg.class,
                                  macroarea == geo,
                                  db.p == source.db,
                                  db.q == target.db,
                                  method == sampleType)
          p = ggplot(plot.df, aes(y=JSD, x=CompType)) +
              geom_violin(fill="dodgerblue") +
              xlab("Type of comparison") + 
              ggtitle(title) + 
              theme_bw() +
              theme(plot.title = element_text(hjust = 0.5))
      }
      else{
          plot.df = df %>% filter(SegmentClass == seg.class,
                                  macroarea == geo,
                                  CompType == comp.type,
                                  method == sampleType)
          p = ggplot(plot.df, aes(y=JSD, x=PtoQ)) +
              geom_violin(fill="dodgerblue") +
              xlab("Type of comparison") + 
              ggtitle(title) + 
              theme_bw() +
              theme(plot.title = element_text(hjust = 0.5))
      }
      
      return(p)
}
```

Now we can do the resampling (500 iterations per parameter set), as well as some plotting.

```{r resampling}
resampling.df = suppressMessages(iter.param(all_dbs_all_segments, k=500))

cols = c("db.p", "db.q")
resampling.df$PtoQ = as.factor(apply(as.data.frame(resampling.df[ ,cols]), 1, paste, collapse = " > "))

# Some cleanup
resampling.df$macroarea = as.factor(ifelse(resampling.df$macroarea == "Eurasia+Africa+South_America+Papunesia+North_America+Australia", "all", as.vector(resampling.df$macroarea)))

# Consonants and vowels, all macroareas, OSPL sampling
## Within (i.e., comparing scrambled to true distributions)
### BDPROTO vs. PHOIBLE
distPlotter(resampling.df,
            "Within BDPROTO > PHOIBLE: OSPL - CV - all areas",
            "consonant+vowel", "all",
            "BDPROTO",
            "PHOIBLE",
            "ospl",
            "within")

### BDPROTO vs. SegBo
distPlotter(resampling.df,
            "Within BDPROTO > SegBo: OSPL - CV - all areas",
            "consonant+vowel", "all",
            "BDPROTO",
            "SegBo",
            "ospl",
            "within")

### PHOIBLE vs. SegBo
distPlotter(resampling.df,
            "Within PHOIBLE > SegBo: OSPL - CV - all areas",
            "consonant+vowel", "all",
            "PHOIBLE",
            "SegBo",
            "ospl",
            "within")


## Across (i.e., comparing similarity across contrasts)
distPlotter(resampling.df,
            "Across databases: OSPL - CV - all areas",
            "consonant+vowel", "all",
            "BDPROTO",
            "PHOIBLE",
            "ospl",
            "across",
            "True-True")

# Consonants and vowels, all macroareas, OIPF sampling
## Within (i.e., comparing scrambled to true distributions)
### BDPROTO vs. PHOIBLE
distPlotter(resampling.df,
            "Within BDPROTO > PHOIBLE: OIPF - CV - all areas",
            "consonant+vowel", "all",
            "BDPROTO",
            "PHOIBLE",
            "oipf",
            "within")

### BDPROTO vs. SegBo
distPlotter(resampling.df,
            "Within BDPROTO > SegBo: OIPF - CV - all areas",
            "consonant+vowel", "all",
            "BDPROTO",
            "SegBo",
            "oipf",
            "within")

### PHOIBLE vs. SegBo
distPlotter(resampling.df,
            "Within PHOIBLE > SegBo: OIPF - CV - all areas",
            "consonant+vowel", "all",
            "PHOIBLE",
            "SegBo",
            "oipf",
            "within")


## Across (i.e., comparing similarity across contrasts)
distPlotter(resampling.df,
            "Across databases: OIPF - CV - all areas",
            "consonant+vowel", "all",
            "BDPROTO",
            "PHOIBLE",
            "oipf",
            "across",
            "True-True")
```

PHOIBLE and SegBo are drawn from a partially overlapping sample of languages. Therefore, and similarity between the two could arise simply because they contain the same languages. Let's check to see how much overlap there indeed is.

```{r check_overlap_phoible_segbo}
pho = droplevels(all_dbs_all_segments[all_dbs_all_segments$Database=="PHOIBLE",])
seg = droplevels(all_dbs_all_segments[all_dbs_all_segments$Database=="SegBo",])

common.langs = intersect(pho$Glottocode, seg$Glottocode)
length(common.langs)/length(unique(seg$Glottocode))
```

As expected, a large number of inventories in SegBo come from languages that also appear in PHOIBLE (~50%). SegBo would only contribute the borrowed segments for any language (and so not the entire inventory), meaning that overlap is smaller than the number of shared languages would suggest. Nevertheless, the most conservative test of the effects of this overlap is to remove all shared languages and rerun the analyses.

```{r resampling_phoible_segbo_noOverlap}
resampling.df.noOverlap = suppressMessages(iter.param(all_dbs_all_segments, k=500, distinctiveSegbo = T))

resampling.df.noOverlap$PtoQ = as.factor(apply(resampling.df.noOverlap[ ,cols], 1, paste, collapse = " > "))
```

Now we rerun the analyses in which we compared the frequencies of segments across the corpora, this time making sure that the languages involved are not shared between PHOIBLE and SegBo.
```{r modeling_noOverlap}
mod.dat.2 = all_dbs_all_segments[!all_dbs_all_segments$SegmentClass %in% c("tone", "vowel"),]

seg.fams = unique(mod.dat.2$family_id[mod.dat.2$Database=="SegBo"])
pho.fams = unique(mod.dat.2$family_id[mod.dat.2$Database=="PHOIBLE"])
bdproto.fams = unique(mod.dat.2$family_id[mod.dat.2$Database=="BDPROTO"])

intersect.fams = intersect(bdproto.fams, pho.fams)
intersect.fams = intersect(intersect.fams, seg.fams)

# Compute counts using only languages that are not shared between PHOIBLE and SegBo 
mod.dat.pho.seg = mod.dat.2 %>%
                  filter(!Glottocode %in% common.langs & 
                          Database != "BDPROTO" & 
                          family_id %in% intersect.fams) %>%
                  group_by(Database, Phoneme) %>%
                  summarize(Frequency=n()) %>%
                  spread(Database, Frequency) %>%
                  replace_na(list(PHOIBLE=0, SegBo=0))

mod.dat.bdproto = mod.dat.2 %>%
                  filter(Database == "BDPROTO" & 
                         family_id %in% intersect.fams) %>%
                  group_by(Phoneme) %>%
                  summarize(BDPROTO=n())

mod.dat.distinctive = left_join(mod.dat.pho.seg, mod.dat.bdproto, by="Phoneme") %>%
                      replace_na(list(BDPROTO=0))

# Scale the variables (sample sizes and scales are different; 
# this makes the numbers comparable)
mod.dat.distinctive$phoible.scaled = scaling.func(mod.dat.distinctive$PHOIBLE)
mod.dat.distinctive$bdproto.scaled = scaling.func(mod.dat.distinctive$BDPROTO)

mod.dat.distinctive.long = data.frame(Phoneme = rep(mod.dat.distinctive$Phoneme, 2), SegBo = rep(mod.dat.distinctive$SegBo, 2), Frequency.scaled = c(mod.dat.distinctive$phoible.scaled, mod.dat.distinctive$bdproto.scaled), Frequency.source = rep(c("PHOIBLE", "BDPROTO"), each=nrow(mod.dat.distinctive)))

#########################################################
# Modeling (7th order polynomial to match prior analyses)
#########################################################

# No overlap, all consonants
mod.nooverlap = glm(SegBo ~ poly(Frequency.scaled,7)*Frequency.source, data = mod.dat.distinctive.long, family="quasipoisson" )
summary(mod.nooverlap)

## Plotting results
hyp.data = expand.grid(Frequency.scaled = seq(0, 10), 
                       Frequency.source = c("PHOIBLE", "BDPROTO"))

preds.hyp = predict(mod.nooverlap, newdata=hyp.data, type="response", se.fit=T)

hyp.data = cbind(hyp.data,
                 SegBo = preds.hyp$fit, 
                 upper = preds.hyp$fit + preds.hyp$se.fit, 
                 lower = preds.hyp$fit - preds.hyp$se.fit)

hyp.data$Frequency.source = toupper(hyp.data$Frequency.source)

poisson.noOverlap.consonants = ggplot(hyp.data, aes(y=SegBo, x=Frequency.scaled, group=Frequency.source,  fill=Frequency.source)) + 
          geom_line() + 
          geom_ribbon(aes(ymin=lower,ymax=upper), alpha=0.7) +
          xlab("Inventory frequency (scaled)") +
          ylab("Predicted SegBo frequency") +
          scale_fill_manual(values=c("lightblue", "darkred"),
                            name="Database") +
          theme_bw()

poisson.noOverlap.consonants

# No overlap, no labiodentals
mod.nooverlap.nold = glm(SegBo ~ poly(Frequency.scaled,7)*Frequency.source, data = mod.dat.distinctive.long[!mod.dat.distinctive.long$Phoneme %in% c("f", "v"),], family="quasipoisson" )
summary(mod.nooverlap.nold)

## Plotting results
hyp.data = expand.grid(Frequency.scaled = seq(0, 10), 
                       Frequency.source = c("PHOIBLE", "BDPROTO"))

preds.hyp = predict(mod.nooverlap.nold, newdata=hyp.data, type="response", se.fit=T)

hyp.data = cbind(hyp.data,
                 SegBo = preds.hyp$fit, 
                 upper = preds.hyp$fit + preds.hyp$se.fit, 
                 lower = preds.hyp$fit - preds.hyp$se.fit)

hyp.data$Frequency.source = toupper(hyp.data$Frequency.source)

poisson.noOverlap.consonants.nold = ggplot(hyp.data, aes(y=SegBo, x=Frequency.scaled, group=Frequency.source,  fill=Frequency.source)) + 
          geom_line() + 
          geom_ribbon(aes(ymin=lower,ymax=upper), alpha=0.7) +
          xlab("Inventory frequency (scaled)") +
          ylab("Predicted SegBo frequency") +
          scale_fill_manual(values=c("lightblue", "darkred"),
                            name="Database") +
          theme_bw()

poisson.noOverlap.consonants.nold


```

The results are nearly identical to the analysis over the full sample of languages. Therefore, the differences between BDPROTO and PHOIBLE are not subject to much interference from the overlap between PHOIBLE and SegBo.

We are interested in the mean behavior of JSD under the different resampling conditions. A first step is presented below, in which BDPROTO and PHOIBLE are compared to SegBo (OSPL sampling, all macroareas, only actual -- not scrambled -- segment counts, consonants and vowels). The goal of this analysis is to determine whether PHOIBLE is significantly more similar to SegBo than BDPROTO (indicating global pressure from borrowability on the development of inventories over time).

```{r modeling_sim_to_segbo}
library(visreg)

# Full inventories
mod.wOverlap.dat = resampling.df %>% filter(CompType=="True-True" & 
                                            macroarea!="all" & 
                                            SegmentClass=="consonant+vowel" &
                                            method=="ospl" &
                                            PtoQ %in% c("BDPROTO > SegBo",
                                                        "PHOIBLE > SegBo"))

cols = c("PtoQ", "macroarea")
mod.wOverlap.dat[cols] = lapply(mod.wOverlap.dat[cols], factor)
colnames(mod.wOverlap.dat)[4] = "Macroarea"

mod.wOverlap.dat$Macroarea = as.factor(ifelse(grepl("_", mod.wOverlap.dat$Macroarea, fixed=T), gsub("_", " ", mod.wOverlap.dat$Macroarea, perl=T), as.vector(mod.wOverlap.dat$Macroarea)))

mod.wOverlap = lm(JSD ~ PtoQ*Macroarea, data = mod.wOverlap.dat)
anova(mod.wOverlap)
qqnorm(resid(mod.wOverlap))

# Some alternative plots
visreg(mod.wOverlap, "PtoQ", by="Macroarea", overlay=T, gg=T) + xlab("Comparison")  + theme_bw()

visreg(mod.wOverlap, "PtoQ", by="Macroarea", gg=T, partial=F, xlab = "Comparison") + xlab("") + theme_bw() + theme(axis.text.x = element_text(angle = 45,  hjust=1))

# No overlap between PHOIBLE and SegBo
resampling.df.noOverlap = resampling.df %>% unite("PtoQ", db.p:db.q, sep = " > ", remove = FALSE)
mod.noOverlap.dat = resampling.df.noOverlap %>% filter(CompType=="True-True" & 
                                                macroarea!="all" & 
                                                SegmentClass=="consonant+vowel" &
                                                method=="ospl" &
                                                PtoQ %in% c("BDPROTO > SegBo",
                                                        "PHOIBLE > SegBo"))

mod.noOverlap.dat[cols] = lapply(mod.noOverlap.dat[cols], factor)
colnames(mod.noOverlap.dat)[4] = "Macroarea"

mod.noOverlap.dat$Macroarea = as.factor(ifelse(grepl("_", mod.noOverlap.dat$Macroarea, fixed=T), gsub("_", " ", mod.noOverlap.dat$Macroarea, perl=T), as.vector(mod.noOverlap.dat$Macroarea)))

mod.noOverlap = lm(JSD ~ PtoQ*Macroarea, data = mod.noOverlap.dat)
anova(mod.noOverlap)
qqnorm(resid(mod.noOverlap))

# Some alternative plots
visreg(mod.noOverlap, "PtoQ", by="Macroarea", overlay=T, gg=T, xlab = "Comparison") + theme_bw()

visreg(mod.noOverlap, "PtoQ", by="Macroarea", gg=T, partial=F, xlab = "Comparison") + theme_bw() + theme(axis.text.x = element_text(angle = 45, vjust = .75, hjust=1))

```

Plots for paper
```{r plots_for_paper}
#################
# Frequency plots 
#################
# Proportions per macroarea
p1.text = p.total.cts + theme(text = element_text(family="Times New Roman", size = 16)) +
              xlab("") +
              ylab("") +
              ggtitle("All segments") +
              coord_flip()

p2.text = p.consonant.cts + theme(text = element_text(family="Times New Roman", size = 16)) +
              xlab("") +
              ylab("") +
              theme(axis.text.y = element_blank()) +
              ggtitle("Consonants") +
              theme(axis.ticks.x = element_blank()) +
              coord_flip()

p3.text = p.vowel.cts + theme(text = element_text(family="Times New Roman", size = 16)) +
              xlab("") +
              ylab("") +
              theme(axis.text.y = element_blank()) +
              ggtitle("Vowels") +
              coord_flip()

plots = list(p1.text, p2.text, p3.text)

remove_axis = theme(axis.title.y = element_blank(), 
                    axis.text.y = element_blank(), 
                    axis.ticks.y = element_blank())

plots[-1] = lapply(plots[-1], function(.p){.p + remove_axis})

prop.plot = ggarrange(plots[[1]], plots[[2]], plots[[3]], nrow=1, ncol=3, common.legend=T, legend="right", widths = c(1.55,1,1))

prop.plot = annotate_figure(prop.plot,
                bottom = text_grob("Proportion of database (%)", 
                                   family="Times New Roman", size = 16),
                left = text_grob("Macroarea", 
                                 family="Times New Roman", rot = 90, size = 16))

ggsave("./plots_for_paper/prop_plot.tiff", plot = prop.plot, device="tiff", units = "in", height=7, width=10)

# Raw counts per corpus
p4.text = all.token.counts + ggtitle("All segments (tokens)") +
                             xlab("") +
                             ylab("") +
                             ylim(0, 100000) +
                             theme(plot.title = element_text(hjust = 0.5), 
                                   text = element_text(family="Times New Roman", size = 14))

p5.text = all.type.counts + ggtitle("All segments (types)") +
                             xlab("") +
                             ylab("") +
                             ylim(0, 3100) +
                             theme(plot.title = element_text(hjust = 0.5), 
                                   text = element_text(family="Times New Roman", size = 14))

p6.text = con.token.counts + ggtitle("Consonants (tokens)") +
                             xlab("") +
                             ylab("") +
                             ylim(0, 100000) + 
                             theme(plot.title = element_text(hjust = 0.5), 
                                   text = element_text(family="Times New Roman", size = 14))

p7.text = con.type.counts + ggtitle("Consonants (types)") +
                             xlab("") +
                             ylab("") +
                             ylim(0, 3100) +
                             theme(plot.title = element_text(hjust = 0.5), 
                                   text = element_text(family="Times New Roman", size = 14))

p8.text = vow.token.counts + ggtitle("Vowels (tokens)") +
                             xlab("") +
                             ylab("") +
                             ylim(0, 100000) +
                             theme(plot.title = element_text(hjust = 0.5), 
                                   text = element_text(family="Times New Roman", size = 14))

p9.text = vow.type.counts + ggtitle("Vowels (types)") +
                             xlab("") +
                             ylab("") +
                             ylim(0, 3100) +
                             theme(plot.title = element_text(hjust = 0.5), 
                                   text = element_text(family="Times New Roman", size = 14))

freq.plot = ggarrange(p4.text, p6.text, p8.text, p5.text, p7.text, p9.text, nrow=2, ncol=3)

freq.plot = annotate_figure(freq.plot,
                bottom = text_grob("Database", 
                                   family="Times New Roman", size = 16),
                left = text_grob("Frequency", 
                                 family="Times New Roman", rot = 90, size = 16))

ggsave("./plots_for_paper/freq_plot.tiff", plot = freq.plot, device="tiff", units = "in", height=7, width=10)

##################
# Poisson analysis 
##################
p10.text = poisson.consonants.all + ggtitle("All consonants") +
              ylab("") +
              xlab("") +
              theme(plot.title = element_text(hjust = 0.5), 
                    text = element_text(family="Times New Roman", size = 14))

p11.text = poisson.consonants.nold.all + ggtitle("No labiodentals") +
              ylab("") +
              xlab("") +
              theme(plot.title = element_text(hjust = 0.5), 
                    text = element_text(family="Times New Roman", size = 14))

p12.text = poisson.noOverlap.consonants + ggtitle("All consonants (no overlap)") +
              ylab("") +
              xlab("") +
              theme(plot.title = element_text(hjust = 0.5), 
                    text = element_text(family="Times New Roman", size = 14))

p13.text = poisson.noOverlap.consonants.nold + ggtitle("No labiodentals (no overlap)") +
              ylab("") +
              xlab("") +
              theme(plot.title = element_text(hjust = 0.5), 
                    text = element_text(family="Times New Roman", size = 14))

poisson.plot = ggarrange(p10.text, p11.text, p12.text, p13.text, legend="right", common.legend=T, nrow=2, ncol=2)

poisson.plot = annotate_figure(poisson.plot,
                bottom = text_grob("Frequency in BDPROTO/PHOIBLE", 
                                   family="Times New Roman", size = 16),
                left = text_grob("Predicted SegBo frequency", 
                                 family="Times New Roman", rot = 90, size = 16))

ggsave("./plots_for_paper/poisson_plot.tiff", plot = poisson.plot, device="tiff", units = "in", height=7, width=10)

# All segments
p14.text = poisson.all + theme(plot.title = element_text(hjust = 0.5), 
                    text = element_text(family="Times New Roman", size = 14))

ggsave("./plots_for_paper/poisson_plot_allsegs.tiff", plot = p14.text, device="tiff", units = "in", height=7, width=10)


##############
# JSD analysis
##############
jsd.plot = visreg(mod.wOverlap, "PtoQ", by="Macroarea", overlay=T, gg=T) + xlab("Comparison")  + theme_bw() + theme(text = element_text(family="Times New Roman", size = 14))

ggsave("./plots_for_paper/jsd_model_results.tiff", plot = jsd.plot, device="tiff", units = "in", height=7, width=10)

#######################################
# Distributions of resampled JSD (OSPL)
#######################################
ospl.sampling = distPlotter(resampling.df[resampling.df$PtoQ %in% c("BDPROTO > PHOIBLE", "BDPROTO > SegBo", "PHOIBLE > SegBo"),],
            "Across databases: OSPL - CV - all areas",
            "consonant+vowel", "all",
            "BDPROTO",
            "PHOIBLE",
            "ospl",
            "across",
            "True-True") + 
            theme(text = element_text(family="Times New Roman", size = 14))

ggsave("./plots_for_paper/jsd_raw_plot.tiff", plot = ospl.sampling, device="tiff", units = "in", height=7, width=10)
```

Save image
```{r save_image}
save.image("./jsd_session.Rdata")
```
    